---
title: "605-HW04-SVD"
author: "Michael Y."
date: "September 22, 2019"
output:
  pdf_document:
    toc: yes
    toc_depth: 3
  html_document:
    highlight: pygments
    theme: cerulean
    code_folding: show
    toc: yes
    toc_float: yes
    toc_depth: 3
classoption: portrait
editor_options:
  chunk_output_type: inline
---
<style>
  .main-container {
    max-width: 1200px !important;
  }
</style>---


# Setup
```{r setup, eval=T, echo=F}
knitr::opts_chunk$set(echo = TRUE)
directory = "C:/Users/Michael/Dropbox/priv/CUNY/MSDS/201909-Fall/DATA605_Larry/20190922_Week04/"
knitr::opts_knit$set(root.dir = directory)

### Make the output wide enough
options(scipen = 999, digits=12, width=150)

### Load some libraries
library(tidyr)
library(dplyr)
library(kableExtra)
library(pracma)
```

``` {r writemtx, eval=T}
#### Function to write Matrix, courtesy of Vinayak Patel :
writeMatrix <- function(x) {  
  begin <- "\\begin{bmatrix}"  
  end   <- "\\end{bmatrix}"  
  X     <-    apply(x, 1, function(x) {
      paste(
          paste(x, collapse = "&"),
          "\\\\"
      )
    }
  )  
  paste(c(begin, X, end), 
        collapse = "")
  }
```

``` {r wnmtx, eval=T}
#### Function to write numerical Matrix, controlling decimals, adapted from above :
wnumMatrix <- function(x) {  
  begin <- "\\begin{bmatrix}"  
  end   <- "\\end{bmatrix}"  
  X     <-    apply(x, 1, function(x) {
      paste(
          paste(format(x, digits = options()$digits), collapse = "&"),
          "\\\\"
      )
    }
  )  
  paste(c(begin, X, end), 
        collapse = "")
  }
```


#### Function to kill tiny values (drop tiny decimal places from the right)
```{r killtiny}
killtiny <- function (INPUTMATRIX, INPUTDIGITS=getOption("digits")) { 
  apply(formatC(x = INPUTMATRIX,
                digits = INPUTDIGITS,
                format = "f"), 
        MARGIN = c(1,2),
        FUN=as.numeric)}
```

\newpage

# Part 1 - Verify Relationship of SVD and Eigenvalues
   
#### matrix A:
```{r rankA, eval=T, echo=F}
A = c(
   1, 2, 3, 
  -1, 0, 4
)
A=matrix(A,2,3,T)
A
```

In this problem, we'll verify using R that SVD and Eigenvalues are related as worked out in the weekly module.   

Given a 3x2 matrix ${A = `r writeMatrix(A)`}$   

write code in R to compute $X = AA^T$ and $Y = A^TA$ .      

Then, compute the eigenvalues and eigenvectors of X and Y using the built-in commans [sic] in R.   

Then, compute the left-singular, singular values, and right-singular vectors of A using the svd command.    

Examine the two sets of singular vectors and show that they are indeed eigenvectors of X and Y.    

In addition, the two non-zero eigenvalues (the 3rd value will be very close to zero, if not zero) of both X and Y are the same and are squares of the non-zero singular values of A.   

Your code should compute all these vectors and scalars and store them in variables.   

Please add enough comments in your code to show me how to interpret your steps.    




\newpage

## Write code in R to compute $X = AA^T$ and $Y = A^TA$ .      

```{r compute-X-and-Y, eval=T}
# Compute X
X = A %*% t(A)    # A*AT is 2x3 * 3x2 --> 2x2
X

# Compute Y
Y = t(A) %*% A    # AT*A is 3x2 * 2x3 --> 3x3
Y
```


${ X = `r writeMatrix(X)` ; Y = `r writeMatrix(Y)`}$

\newpage


## Then, compute the eigenvalues and eigenvectors of X and Y using the built-in commans [sic] in R.   

```{r get-eigens, eval=t}
# Get the eigenvalues and eigenvectors of X
eigX = eigen(X)
eigX
X_eigenval1 = as.matrix(eigX$values)
X_eigenval1

# kill the tiny part of X eigenvalues
X_eigenval2 = killtiny(X_eigenval1)
X_eigenval2

# Get the eigenvalues and eigenvectors of Y 
eigY = eigen(Y)
eigY
Y_eigenval1 = as.matrix(eigY$values)
Y_eigenval1

# kill the tiny part of Y eigenvalues
Y_eigenval2 = killtiny(Y_eigenval1)
Y_eigenval2
```



\newpage


## The two non-zero eigenvalues (the 3rd value will be very close to zero, if not zero) of both X and Y are the same
```{r compare-eigenvalues}
# examine difference between eigenvalues for X and Y
# add a zero to pretend there is a third eigenvalue for X, so the matrices can be compared
X_eigenval3 = rbind(X_eigenval2,0)
X_eigenval3

# difference of X eigenvalues (with appended zero) vs. Y eigenvalues:
X_eigenval3 - Y_eigenval2

# Are the eigenvalues equal?
all.equal(X_eigenval3, Y_eigenval2)

```

Thus, the two eigenvalues for $X$,  ${eig(X)=`r writeMatrix(X_eigenval2)`}$ ,    
are equal to the first two eigenvalues for $Y$,  ${eig(Y)=`r writeMatrix(Y_eigenval2)`}$ .


\newpage


### What are these eigenvalues (in analytic terms) ?
#### Get the characteristic polynomials:

```{r get-char-polynomials}
Xpoly = charpoly(X)
Xpoly
Ypoly = charpoly(Y)
Ypoly
```

So, the eigenvalues for X solve $t^2-31t^2+117=0$ ,    
and the eigenvalues for Y solve $t^3-31t^2+117t=0$  .    
   
By the quadratic formula, the solution for eigenvalues of X is 
$$eigvals_X={\frac{ 31 \pm \sqrt{(-31)^2-4\cdot1\cdot117}}{2} =  \frac{ 31 \pm \sqrt{493}}{2}}$$  

(The square root cannot be factored further as $493=29*17$ , both of which are prime.)   

The eigenvalues for Y are going to be the above pair of values as well as 0, as Y is singular.  

\newpage


#### Check that these match the eigenvalues
```{r confirm-quadratic-formula}
# check first eigenval
eigval1 = (31 + sqrt(493))/2
eigval1
all.equal(X_eigenval2[1],eigval1)
# check second eigenval
eigval2 = (31 - sqrt(493))/2
eigval2
all.equal(X_eigenval2[2],eigval2)
```

#### Get the roots of the polynomials numerically
```{r check-polyroots, warning=F}
# Two roots of the characteristic polynomial for X:
Xroots = t(t(as.numeric(rev(polyroot(rev(Xpoly))))))
Xroots

# Three roots of the characteristic polynomial for Y:
Yroots = t(t(as.numeric(rev(polyroot(rev(Ypoly))))))
Yroots
```



\newpage

 
## Compute the left-singular, singular values, and right-singular vectors of A using the svd command: 


```{r get-svd}
A_svd = svd(x=A, nu=2, nv=3)   # we need to specify nv=3 so function will return the entire V
# left side
U = A_svd$u               # U is 2x2
print('U: ')
U

# diagonal entries
D = A_svd$d               # D has 2 entries
print('D: ')
D

# sqrt of diagonal entries
sqrt_D = as.matrix(D^0.5)
print('sqrt(D): ')
sqrt_D

# diagonal matrix
DI = D *  eye(length(D))   # Note this is "*" rather than "%*%" because 
                           # we just want to put the diagonal entries into I
print('Diag: ')
DI

# DDD needs to be 2x3 because V is 3x3
DDD = cbind(DI,0)
print('D as 2x3: ')
DDD

# right side
V = A_svd$v               # V is 3x3
print('V: ')
V
```

$$ U = `r writeMatrix(U)` $$   
$$ D = `r writeMatrix(DI)` $$ 
$$ V = `r writeMatrix(V)` $$
To get the dimensions correct for multiplication, we need to add a blank column to D:  

$$DDD = `r writeMatrix(DDD)`$$

\newpage


## The two non-zero eigenvalues of both X and Y are squares of the non-zero singular values of A:

```{r check-squares}
D_squared = as.matrix(D^2,2,1)
D_squared
# Compare against non-zero eigenvalues
X_eigenval2
# Are they almost same?
X_eigenval2 - D_squared
all.equal(X_eigenval2,D_squared)
killtiny(X_eigenval2)==killtiny(D_squared)
```

\newpage


## Examine the two sets of singular vectors and show that they are indeed eigenvectors of X and Y.    

Remember that eigenvectors can be negated in sign -- it just flips the direction -- so we may have to flip signs on columns to check

### Check U against eigenvectors of X:

```{r check-eigenvec-X}
# display U
U
# display eigenvectors of X:
X_eigvecs = eigX$vectors
X_eigvecs

# we need to flip the signs on the first column of the eigenvectors to get a match
# Matrix to flip the signs in column 1:
FlipSigns_col1 = matrix(c(-1,-1,1,1),2,2,F)
FlipSigns_col1
X_eigvecs_flipsign1 = X_eigvecs * FlipSigns_col1   # Note that this uses elementwise "*" 
                                                   # rather than "%*%"
X_eigvecs_flipsign1

# check if this is almost equal to U
all.equal(X_eigvecs_flipsign1, U)
X_eigvecs_flipsign1 - U
# If we kill the decimals far to the right, do they match?
killtiny(X_eigvecs_flipsign1) == killtiny(U)
```

\newpage


### Check that the eigenvectors (U) and the eigenvalues for X actually work: $X u_i = \lambda_{X_i} u_i$

``` {r check-X-and-U}
# check the first eigenvalue and eigenvector
X_lhs1=X %*% U[,1]
X_lhs1
X_rhs1=(as.matrix(X_eigenval2[1] * U[,1],2,1))
X_rhs1
all.equal(X_lhs1,X_rhs1)

# check the second eigenvalue and eigenvector
X_lhs2=X %*% U[,2]
X_lhs2
X_rhs2=(as.matrix(X_eigenval2[2] * U[,2],2,1))
X_rhs2
all.equal(X_lhs2,X_rhs2)

```



\newpage


### Check V against eigenvectors of Y:

```{r check-eigenvec-V}
# display V:
V
# display eigenvectors of Y:
Y_eigvecs = eigY$vectors
Y_eigvecs

# we need to flip the signs on the first and third columns of the eigenvectors to get a match
# Matrix to flip the signs in column 1
FlipSigns_col13 = matrix(c(-1,-1,-1,1,1,1,-1,-1,-1),3,3,F)
FlipSigns_col13
Y_eigvecs_flipsign13 = Y_eigvecs * FlipSigns_col13   # Note that this uses elementwise "*" 
                                                     # rather than "%*%"
Y_eigvecs_flipsign13

# check if this is almost equal to V
all.equal(Y_eigvecs_flipsign13, V)
Y_eigvecs_flipsign13 - V
# If we kill the decimals far to the right, do they match?
killtiny(Y_eigvecs_flipsign13) == killtiny(V)
```


\newpage


### Check that the eigenvectors and eigenvalues for Y actually work: $Y v_i = \lambda_{Y_i} v_i$

``` {r check-Y-and-V}
# check the first eigenvalue and eigenvector
Y_lhs1=Y %*% V[,1]
Y_lhs1
Y_rhs1=(as.matrix(Y_eigenval2[1] * V[,1],3,1))
Y_rhs1
all.equal(Y_lhs1,Y_rhs1)

# check the second eigenvalue and eigenvector
Y_lhs2=Y %*% V[,2]
Y_lhs2
Y_rhs2=(as.matrix(Y_eigenval2[2] * V[,2],3,1))
Y_rhs2
all.equal(Y_lhs2,Y_rhs2)

# check the third eigenvalue (here, zero) and eigenvector
Y_lhs3=Y %*% V[,3]
Y_lhs3
Y_rhs3=(as.matrix(Y_eigenval2[3] * V[,3],3,1))
Y_rhs3
all.equal(Y_lhs3,Y_rhs3)
# are they exactly equal if we kill the tiny bits
killtiny(Y_lhs3)==killtiny(Y_rhs3)
```


```{r reduceDigits,echo=F}
options(digits=4)
```

\newpage


## Check that the SVD works: $A = U D V^T$
$$A=U \cdot D \cdot V^T = `r wnumMatrix(U)` `r wnumMatrix(DDD)` `r wnumMatrix(t(V))` $$
```{r restoreDigits,echo=F}
options(digits=12)
```

```{r check_svd}
# confirm that A = U * DDD * t(V)
result = U %*% DDD %*% t(V)
result

# is it approximately equal to A ?
all.equal(result,A)

# If we get rid of the tiny bits, is it exactly equal to A?
result2 = killtiny(result)
result2

# do they exactly match?
A == result2

```

***
\newpage
# Part 2 - Inverse using co-factors

Using the procedure outlined in section 1 of the weekly handout, write a function to compute the inverse of a well-conditioned full-rank square matrix using co-factors.   

In order to compute the co-factors, you may use built-in commands to compute the determinant.  

Your function should have the following signature:  

$B = myinverse(A)$  

where $A$ is a matrix and $B$ is its inverse and $A\cdot B = I$.   

The off-diagonal elements of $I$ should be close to zero, if not zero.   

Likewise, the diagonal elements should be close to 1, if not 1.   

Small numerical precision errors are acceptable but the function myinverse should be correct and must use co-factors and determinant of A to compute the inverse.  


\newpage


##  Function myinverse
```{r myinverse, eval=T}
myinverse <- function(A){
### Function to compute the inverse of a well-conditioned full-rank square matrix using co-factors
  
  # confirm that A is of type "matrix"
  if (class(A) != "matrix") stop ("Parameter must be of type MATRIX.")
  
  # confirm that A is square
  Arows = nrow(A)
  Acols = ncol(A)
  if (Arows != Acols) stop ("Parameter must be a SQUARE matrix.")
  
  # check that A is non-singular
  Adet = det(A)
  epsilon = 1e-10
  if (abs(Adet) < epsilon) stop ("Parameter must be NON-singular.")
  
  # check that A is well-conditioned
  # condition number is obtained from the svd - 
  # it is the ratio of the largest and smallest singular values
  Acond = cond(A)
  if (Acond > 1/epsilon) stop ("Parameter must be WELL-conditioned.")

  # Create an identity matrix of the same size as A, in which to populate the cofactors:
  detcofactors = zeros(Arows)
  
  for (i in 1:Arows){
    
    for (j in 1:Acols){
      
      # derive the cofactor by dropping the current row and column, using A[-i,-j]
      # in the case of a 2x2 matrix, this would yield back a scalar, 
      # which would cause problems for the det() function.
      # so, ensure that the cofactor is a matrix, even if it is a 1x1 matrix
      cofactor = matrix(A[-i,-j],(Arows-1),(Acols-1),T)
      
      # compute the determinant of the cofactors, 
      # multiplied by a negative sign in the case of odd (row+column)
      detcofactors[i,j] =  det(cofactor) * (-1)^(i+j)
      
    } # for j
    
  } # for i    
  
  # The inverse of A is calculated as the transpose of detcofactors, divided by the determinant of A
  Ainverse <- t(detcofactors)/Adet

  return(Ainverse)
}

```





\newpage


### Create some matrices for testing:

```{r testmatrices, eval=T}
# Create a matrix containing the single element, 0
A0 = matrix(0)
A0

# Create a matrix containing the single element, 7
A1 = matrix(7)
A1

# Create a 2x2 non-singular matrix
A22 = c(
  1,2,
  2,1
)
A22 = matrix(A22,2,2,T)
A22

# Create a 2x3 non-square matrix
A23 = c(
  1,2,3,
  6,5,4
)
A23 = matrix(A23,2,3,T)
A23

# Create a 3x3 non-singular matrix
A33 = c(
1, 2, 3,
0, 4, 5,
0, 0, 6
)
A33 = matrix(A33,nrow=3,byrow=T)
A33

# Create a 3x3 singular matrix
A33sing = c(
  2,    2,   -1,
  2,    4,    6,
 -1,    6,   25
)

A33sing = matrix(A33sing,nrow=3,byrow=T)
A33sing
# zero determinant
det(A33sing)


# Create a 3x3 ill-conditioned matrix
A33cond = c(
  2,    2,   -1,
  2,    4,    6,
 -1,    6,   25.00000001
)
A33cond = matrix(A33cond,nrow=3,byrow=T)
A33cond
# Tiny determinant
det(A33cond)
# huge condition number
cond(A33cond)


```
***
\newpage


### Test a 1x1 matrix containing just the element "0":
$$ A_0 = `r writeMatrix(A0)` $$ 
```{r testA0, eval=T}
# compute myinverse
myA0inv = try(myinverse(A0))

```
***
### Test a 2x3 matrix:

$$ A_{2x3} = `r writeMatrix(A23)` $$ 
```{r testA23, eval=T}
# compute myinverse
myA23inv = try(myinverse(A23))
```

***
### Test a 3x3 *singular* matrix:

$$ A_{3x3-sing} = `r writeMatrix(A33sing)` $$ 

```{r testA33ns, eval=T}
# compute myinverse
myA33nsinv = try(myinverse(A33ns))

```

***
### Test a 3x3 *ill-conditioned* matrix:

$$ A_{3x3-ill-cond} = `r writeMatrix(A33cond)` $$ 

```{r testA33cond, eval=T}
# compute myinverse
myA33condinv = try(myinverse(A33cond))

```


***
\newpage


### Test a 1x1 matrix containing just the element "7":
$$ A_{1x1} = `r writeMatrix(A1)` $$ 
```{r testA1, eval=T}
# compute myinverse
myA1inv = myinverse(A1)
myA1inv

# check to see if it gives back the identity
checkA1 = A1 %*% myA1inv
checkA1
all.equal(checkA1,eye(nrow(A1)))


# does myinverse come quite close to the official inverse?
myA1inv - inv(A1)
all.equal(myA1inv,inv(A1))

killtiny(myA1inv)
inv(A1)

# does the inverse of the inverse of A1 give you back A1 ?
doubleinverseA1 = myinverse(myinverse(A1))
doubleinverseA1
all.equal(doubleinverseA1,A1)
```

***
\newpage

### Test a 2x2 non-singular matrix:

$$ A_{2x2} = `r writeMatrix(A22)` $$ 
```{r testA22, eval=T}
# compute myinverse
myA22inv = myinverse(A22)
myA22inv

# check to see if it gives back the identity
checkA22 = A22 %*% myA22inv
checkA22
all.equal(checkA22,eye(nrow(A22)))


# does myinverse come quite close to the official inverse?
inv(A22)
myA22inv - inv(A22)
all.equal(myA22inv,inv(A22))

killtiny(myA22inv)
inv(A22)

# does the inverse of the inverse of A22 give you back A22 ?
doubleinverseA22 = myinverse(myinverse(A22))
doubleinverseA22
all.equal(doubleinverseA22,A22)
```


***
\newpage

### Test a 3x3 non-singular matrix:

$$ A_{3x3} = `r writeMatrix(A33)` $$ 
```{r testA33, eval=T}
# compute myinverse
myA33inv = myinverse(A33)
myA33inv

# check to see if it gives back the identity
checkA33 = A33 %*% myA33inv
checkA33
all.equal(checkA33,eye(nrow(A33)))


# does myinverse come quite close to the official inverse?
inv(A33)
myA33inv - inv(A33)
all.equal(myA33inv,inv(A33))

killtiny(myA33inv)
inv(A33)

# does the inverse of the inverse of A33 give you back A33 ?
doubleinverseA33 = myinverse(myinverse(A33))
doubleinverseA33
all.equal(doubleinverseA33,A33)
```
